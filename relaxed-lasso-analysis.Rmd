---
title: "Relaxed Lasso Analysis"
author: "DJ McDonald"
date: "29/12/2022"
output: html_document
params: 
  #tracts: "wml_data_mri_tractprofiles_n60_run1_20220816.csv" # run1
  tracts: "wml_data_mri_tractprofiles_n59_run2_20220816.csv" #run2
---

# Setup and data processing: Run `r stringr::str_extract(params$tracts, "(?<=run).")`

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE
)
```

```{r, eval=FALSE, echo=TRUE}
# Required packages
install.packages("tidyverse")
install.packages("glmnet")
install.packages("lme4")
install.packages("remotes")
```

```{r data-loading}
library(glmnet)
library(tidyverse)
recog <- read_csv("wml_data_beh_recog_n60_20220607.csv")
wr <- read_csv("wml_data_beh_write_n60_20220607.csv")
tracts <- read_csv(params$tracts)

# use fractional anisotropy
fa <- tracts %>% dplyr::select(subID, tractname, nodeID, fa)
fa_sub <- fa %>%
  filter(
    str_detect(tractname, "SLF") |
      str_detect(tractname, "MDLF") |
      str_detect(tractname, "TPC") |
      str_detect(tractname, "Arc") |
      str_detect(tractname, "IFOF") |
      str_detect(tractname, "ILF") 
    
  ) %>%
  mutate(gr = case_when(
    str_detect(tractname, "SLF") ~ "Dorsal",
    str_detect(tractname, "IFOF") | str_detect(tractname, "ILF") ~ "Ventral",
    TRUE ~ "PVP"
  ))
rm(tracts, fa)
fa_wide_means <- fa_sub %>%
  filter(nodeID > 20, nodeID < 181) %>%
  group_by(subID, tractname) %>%
  summarise(fa = mean(fa, na.rm = TRUE)) %>%
  pivot_wider(names_from = tractname, values_from = fa)
fa_wide <- fa_sub %>%
  filter(nodeID > 20, nodeID < 181) %>%
  dplyr::select(-gr) %>%
  pivot_wider(names_from = c(tractname, nodeID), values_from = fa)

recog_resp <- recog %>%
  group_by(subID) %>%
  summarise(
    rt = mean(RT[acc == 1], na.rm = TRUE),
    acc = mean(acc == 1, na.rm = TRUE)
  )
```

# Remove some data 

* Outliers

```{r, fig.show='hold', out.width="45%"}
plot(recog_resp$acc, recog_resp$rt)
bad_outlier <- recog_resp$subID[recog_resp$acc <= .50]
```

* Some subjects that are missing retest data or other MRI processing issues.

```{r kill-outlier}
missing_tracts <- c(25, 31, 32, 42) 
missing_run2 <- c(53) 
bad_testretest <- c(46, 50, 54, 56)
brain_anomaly <- c(60)
remove_ids <- c(
  bad_outlier, 
  missing_tracts, 
  brain_anomaly, 
  missing_run2, 
  bad_testretest
)

fa_sub <- fa_sub %>% 
  filter(!subID %in% remove_ids)
fa_wide <- fa_wide %>% 
  filter(!subID %in% remove_ids)
fa_wide_means <- fa_wide_means %>% 
  filter(!subID %in% remove_ids)
recog_resp <- recog_resp %>% 
  filter(!subID %in% remove_ids)
wr <- wr %>% 
  filter(!subID %in% remove_ids)
```


# Calculate the response slopes

```{r response}
fits <- wr %>%
  group_by(subID) %>%
  group_modify( ~ {
    as.data.frame(
      summary(
        lme4::lmer(
          formula = drawduration ~ block + (1 | stimulus), 
          data = .x
        )
      )$coefficients[2, , drop = FALSE]
    )
  })

all_resp <- full_join(recog_resp, fits) %>%
  dplyr::select(subID, rt, acc, Estimate) %>%
  rename(learn = Estimate) %>%
  mutate(learn = -learn)
```


# Relaxed lasso on means for selected tracks

```{r}
y <- as.matrix(all_resp %>% dplyr::select(-subID))
x <- fa_wide_means %>% 
  ungroup() %>% 
  dplyr::select(-subID) %>% 
  as.matrix()
```

```{r, warning=FALSE}
mod_acc <- cv.glmnet(
  x, y[ ,"acc"], 
  relax = TRUE, gamma = 0, nfolds = nrow(x) # LOOCV
)
mod_learn <- cv.glmnet(
  x, y[ ,"learn"], 
  relax = TRUE, gamma = 0, nfolds = nrow(x)
)

mean_model_lasso <- lapply(
  list(acc = mod_acc, learn = mod_learn), 
  coef, s = "lambda.min") %>%
  lapply(as.vector) %>%
  bind_cols() %>%
  mutate(var = c("(Intercept)", colnames(x))) %>%
  pivot_longer(-var) %>%
  filter(abs(value) > 0)

ggplot(mean_model_lasso, aes(value, var, color = name)) +
  geom_point() + 
  theme_bw() +
  geom_vline(xintercept = 0) +
  scale_color_brewer(palette = "Set1") +
  ylab("")
```

## Confidence intervals for this fit.

Because $n > p$, technically, the OLS intervals are valid.

```{r glmnet-cis}
lm_acc <- lm(acc ~ . , bind_cols(acc = y[ ,"acc"], x))
lm_learn <- lm(learn ~ ., bind_cols(learn = y[ ,"learn"] , x))

mean_model_lasso <- left_join(
  mean_model_lasso,
  bind_rows(
    as_tibble(confint(lm_acc)) %>% 
      mutate(name = "acc", var = names(coef(lm_acc))),
    as_tibble(confint(lm_learn)) %>% 
      mutate(name = "learn", var = names(coef(lm_learn)))
  )
)

better_labels = c(
  acc = "Recognition Accuracy", 
  learn = "Drawing Duration"
)
  
ggplot(mean_model_lasso, aes(y = var, color = var)) +
  geom_point(aes(x = value)) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`)) +
  facet_wrap(~ name, scales = "free", 
             labeller = labeller(name = better_labels)) +
  theme_bw() +
  geom_vline(xintercept = 0) +
  theme(legend.position = "none") +
  scale_color_brewer(palette = "Dark2")
```

## See how well the regions for drawing (learning) predict accuracy

I think the right way to do this is not to use *the estimated model* from drawing to predict accuracy, but to use *the selected regions* from the drawing model. Then we refit accuracy, using only those regions, but have new slope/intercepts. Otherwise, things are on the wrong scale.


```{r}
# predsdraw <- predict(mod_learn, newx = x, s = mod_learn$lambda.min)
predsacc <- predict(mod_acc, newx = x, s = "lambda.min")
acc_model_with_draw_covariates <- 
  lm(acc ~ ., bind_cols(
    acc = y[,"acc"], 
    x[, predict(mod_learn, s="lambda.min", type = "nonzero")$lambda.min,
      drop=FALSE]))
acc_model_with_draw_covariates_predictions <- predict(acc_model_with_draw_covariates)

mse1 = mean((y[,"acc"] - predsacc)^2) # accuracy model for accuracy
mse2 = mean((y[,"acc"] - acc_model_with_draw_covariates_predictions)^2)

perc_worse <- (mse2 / mse1 - 1) * 100 
```


Doing this, the predictions using the drawing regions are about `r round(perc_worse)`% worse.

```{r plt-preds}
bind_cols(accuracy = y[,"acc"], 
          `drawing model` = acc_model_with_draw_covariates_predictions,
          `accuracy model` = predsacc) %>%
  pivot_longer(-accuracy, values_to = "predicted value") %>%
  ggplot(aes(x = `predicted value`, y = accuracy)) + 
  geom_point(aes(color = name, shape = name)) +
  theme_bw() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom", 
        legend.title = element_blank()) +
  geom_abline(slope = 1, intercept = 0)
```

```{r tab1-fun, echo=FALSE}
tab1_fun <- function(name, yvar, lasso_mod, lm_mod) {
  mse <- function(a, b) mean((a - b)^2)
  n <- length(y[,yvar])
  b1 = coef(lasso_mod, s = "lambda.min")
  plasso <- predict(lasso_mod, newx = x, s = "lambda.min")
  nz <- which(abs(b1) > 0)[-1]
  ses = summary(lm_mod)$coefficients[nz, 2]
  R2 = 1 - mse(y[,yvar], plasso) / (var(y[,yvar]) * (n - 1) / n)
  AdjR2 = 1 - (1 - R2) * (n - 1) / (n - sum(abs(b1) > 0))
  # browser()
  mat = cbind(b1[nz], ses, c(R2, rep(NA, length(nz)-1)), c(AdjR2, rep(NA, length(nz)-1)))
  colnames(mat) <- c("beta_hat", "S.E.", "R2", "Adj R2")
  rownames(mat) <- rownames(b1)[nz]
  cat("\n", name, "\n\n")
  print(mat)
  cat("\n")
  invisible(mat)
}
```

```{r acc-model-table, echo=FALSE}
summary(acc_model_with_draw_covariates)
```

## Table 1



```{r, echo=FALSE}
tab1_fun("Drawing learning", "learn", mod_learn, lm_learn)
tab1_fun("Visual recognition learning", "acc", mod_acc, lm_acc)
```

## J-test and Cox test to compare non-nested models

Reference: 

Davidson, R., & MacKinnon, J. G. (1981). SEVERAL TESTS FOR MODEL SPECIFICATION IN THE PRESENCE OF ALTERNATIVE HYPOTHESES. Econometrica (Pre-1986), 49(3), 781.

```{r jtest}
library(lmtest)
jdata <- as.data.frame(cbind(acc = y[, "acc"], x))
learn_vars <- which(abs(coef(mod_learn, s="lambda.min"))[-1,] > 0)
acc_vars <- which(abs(coef(mod_acc, s="lambda.min"))[-1,] > 0)
lform_learn <- as.formula(
  paste("acc ~", paste(colnames(x)[learn_vars], collapse = " + "))
)
lform_acc <- as.formula(
  paste("acc ~", paste(colnames(x)[acc_vars], collapse = " + "))
)
jtest(lform_acc, lform_learn, data = jdata)
coxtest(lform_acc, lform_learn, data = jdata)
```

### Estimated model summary for using the learn regions to predict accuracy

```{r wrong-model-summary}
summary(lm(lform_learn, data = jdata))
```
