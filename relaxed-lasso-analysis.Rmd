---
title: "Relaxed Lasso Analysis"
author: "DJ McDonald"
date: "29/06/2022"
output: html_document
params: 
  tracts: "wml_data_mri_tractprofiles_n60_run1_20220816.csv" # run1
 #tracts: "wml_data_mri_tractprofiles_n59_run2_20220816.csv" #run2
---

# Setup and data processing

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE
)
```

```{r, eval=FALSE, echo=TRUE}
# Required packages
install.packages("tidyverse")
install.packages("glmnet")
install.packages("lme4")
install.packages("remotes")
```

```{r data-loading}
library(glmnet)
library(tidyverse)
recog <- read_csv("wml_data_beh_recog_n60_20220607.csv")
wr <- read_csv("wml_data_beh_write_n60_20220607.csv")
tracts <- read_csv(params$tracts)

# use fractional anisotropy
fa <- tracts %>% dplyr::select(subID, tractname, nodeID, fa)
fa_sub <- fa %>%
  filter(
    str_detect(tractname, "SLF") |
      str_detect(tractname, "MDLF") |
      str_detect(tractname, "TPC") |
      str_detect(tractname, "Arc") |
      str_detect(tractname, "IFOF") |
      str_detect(tractname, "ILF") 
    
  ) %>%
  mutate(gr = case_when(
    str_detect(tractname, "SLF") ~ "Dorsal",
    str_detect(tractname, "IFOF") | str_detect(tractname, "ILF") ~ "Ventral",
    TRUE ~ "PVP"
  ))
rm(tracts, fa)
fa_wide_means <- fa_sub %>%
  filter(nodeID > 20, nodeID < 181) %>%
  group_by(subID, tractname) %>%
  summarise(fa = mean(fa, na.rm = TRUE)) %>%
  pivot_wider(names_from = tractname, values_from = fa)
fa_wide <- fa_sub %>%
  filter(nodeID > 20, nodeID < 181) %>%
  dplyr::select(-gr) %>%
  pivot_wider(names_from = c(tractname, nodeID), values_from = fa)

recog_resp <- recog %>%
  group_by(subID) %>%
  summarise(
    rt = mean(RT[acc == 1], na.rm = TRUE),
    acc = mean(acc == 1, na.rm = TRUE)
  )
```

# Remove some data 

* Outliers

```{r, fig.show='hold', out.width="45%"}
plot(recog_resp$acc, recog_resp$rt)
bad_outlier <- recog_resp$subID[recog_resp$acc <= .50]
```

* Some subjects that are missing retest data or other MRI processing issues.

```{r kill-outlier}
missing_tracts <- c(25, 31, 32, 42) 
missing_run2 <- c(53) 
bad_testretest <- c(46, 50, 54, 56)
brain_anomaly <- c(60)
remove_ids <- c(
  bad_outlier, 
  missing_tracts, 
  brain_anomaly, 
  missing_run2, 
  bad_testretest
)

fa_sub <- fa_sub %>% 
  filter(!subID %in% remove_ids)
fa_wide <- fa_wide %>% 
  filter(!subID %in% remove_ids)
fa_wide_means <- fa_wide_means %>% 
  filter(!subID %in% remove_ids)
recog_resp <- recog_resp %>% 
  filter(!subID %in% remove_ids)
wr <- wr %>% 
  filter(!subID %in% remove_ids)
```


# Calculate the response slopes

```{r response}
fits <- wr %>%
  group_by(subID) %>%
  group_modify( ~ {
    as.data.frame(
      summary(
        lme4::lmer(
          formula = drawduration ~ block + (1 | stimulus), 
          data = .x
        )
      )$coefficients[2, , drop = FALSE]
    )
  })

all_resp <- full_join(recog_resp, fits) %>%
  dplyr::select(subID, rt, acc, Estimate) %>%
  rename(learn = Estimate) %>%
  mutate(learn = -learn)
```


# Relaxed lasso on means for selected tracks

```{r}
y <- as.matrix(all_resp %>% dplyr::select(-subID))
x <- fa_wide_means %>% 
  ungroup() %>% 
  dplyr::select(-subID) %>% 
  as.matrix()
```

```{r, warning=FALSE}
mod_acc <- cv.glmnet(
  x, y[ ,"acc"], 
  relax = TRUE, gamma = 0, nfolds = nrow(x) # LOOCV
)
mod_learn <- cv.glmnet(
  x, y[ ,"learn"], 
  relax = TRUE, gamma = 0, nfolds = nrow(x)
)

mean_model_lasso <- lapply(
  list(acc = mod_acc, learn = mod_learn), 
  coef, s = "lambda.min") %>%
  lapply(as.vector) %>%
  bind_cols() %>%
  mutate(var = c("(Intercept)", colnames(x))) %>%
  pivot_longer(-var) %>%
  filter(abs(value) > 0)

ggplot(mean_model_lasso, aes(value, var, color = name)) +
  geom_point() + 
  theme_bw() +
  geom_vline(xintercept = 0) +
  scale_color_brewer(palette = "Set1") +
  ylab("")
```

## Confidence intervals for this fit.

Because $n > p$, technically, the OLS intervals are valid.

```{r glmnet-cis}
lm_acc <- lm(acc ~ . , bind_cols(acc = y[ ,"acc"], x))
lm_learn <- lm(learn ~ ., bind_cols(learn = y[ ,"learn"] , x))

mean_model_lasso <- left_join(
  mean_model_lasso,
  bind_rows(
    as_tibble(confint(lm_acc)) %>% 
      mutate(name = "acc", var = names(coef(lm_acc))),
    as_tibble(confint(lm_learn)) %>% 
      mutate(name = "learn", var = names(coef(lm_learn)))
  )
)

better_labels = c(
  acc = "Recognition Accuracy", 
  learn = "Drawing Duration"
)
  
ggplot(mean_model_lasso, aes(y = var, color = var)) +
  geom_point(aes(x = value)) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`)) +
  facet_wrap(~ name, scales = "free", 
             labeller = labeller(name = better_labels)) +
  theme_bw() +
  geom_vline(xintercept = 0) +
  theme(legend.position = "none") +
  scale_color_brewer(palette = "Dark2")
```

## See how well the regions for drawing (learning) predict accuracy

I think the right way to do this is not to use *the estimated model* from drawing to predict accuracy, but to use *the selected regions* from the drawing model. Then we refit accuracy, using only those regions, but have new slope/intercepts. Otherwise, things are on the wrong scale.


```{r}
# predsdraw <- predict(mod_learn, newx = x, s = mod_learn$lambda.min)
predsacc <- predict(mod_acc, newx = x, s = "lambda.min")
acc_model_with_draw_covariates <- 
  lm(acc ~ ., bind_cols(
    acc = y[,"acc"], 
    x[, predict(mod_learn, s="lambda.min", type = "nonzero")$lambda.min,
      drop=FALSE])) %>%
  predict(newx = x)

mse1 = mean((y[,"acc"] - predsacc)^2) # accuracy model for accuracy
mse2 = mean((y[,"acc"] - acc_model_with_draw_covariates)^2)

perc_worse <- (mse2 / mse1 - 1) * 100 
```


Doing this, the predictions using the drawing regions are about `r round(perc_worse)`% worse.

```{r plt-preds}
bind_cols(accuracy = y[,"acc"], 
          `drawing model` = acc_model_with_draw_covariates,
          `accuracy model` = predsacc) %>%
  pivot_longer(-accuracy, values_to = "predicted value") %>%
  ggplot(aes(x = `predicted value`, y = accuracy)) + 
  geom_point(aes(color = name, shape = name)) +
  theme_bw() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom", 
        legend.title = element_blank()) +
  geom_abline(slope = 1, intercept = 0)
```
