---
title: "next-steps"
author: "DJM"
date: "15/04/2022"
output: 
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r, eval=FALSE, echo=TRUE}
# Required packages
install.packages("tidyverse")
install.packages("glmnet")
install.packages("lme4")
install.packages("selectiveInference")
install.packages("remotes")
remotes::install_github("dajmcdon/sparsegl")
```

```{r data-loading} 
library(glmnet)
library(tidyverse)
recog <- read_csv("wml_data_beh_recog_n39_20220314.csv")
wr <- read_csv("wml_data_beh_write_n39_20220314.csv")
tracts <- read_csv("wml_data_mri_tractprofiles_n39_20220314.csv")

# use fractional anisotropy
fa <- tracts %>% select(subID, tractname, nodeID, fa)
fa_sub <- fa %>%
  filter(
    str_detect(tractname, "SLF") |
      str_detect(tractname, "MDLF") |
      str_detect(tractname, "TPC") |
      str_detect(tractname, "pArc") |
      str_detect(tractname, "IFOF") |
      str_detect(tractname, "ILF") 
  ) %>%
  mutate(gr = case_when(
    str_detect(tractname, "SLF") ~ "Dorsal",
    str_detect(tractname, "IFOF") | str_detect(tractname, "ILF") ~ "Ventral",
    TRUE ~ "PVP"
  ))
rm(tracts, fa)
fa_wide_means <- fa_sub %>%
  filter(nodeID > 20, nodeID < 181) %>%
  group_by(subID, tractname) %>%
  summarise(fa = mean(fa, na.rm = TRUE)) %>%
  pivot_wider(names_from = tractname, values_from = fa)
fa_wide <- fa_sub %>%
  filter(nodeID > 20, nodeID < 181) %>%
  select(-gr) %>%
  pivot_wider(names_from = c(tractname, nodeID), values_from = fa)

recog_resp <- recog %>%
  group_by(subID) %>%
  summarise(rt = mean(RT[acc == 1], na.rm=TRUE),
            acc = mean(acc == 1, na.rm=TRUE))
```

# Should we log transform `acc`? Are there outliers?

```{r, fig.show='hold', out.width="45%"}
plot(density(recog_resp$acc))
plot(recog_resp$acc, recog_resp$rt)
bad_outlier <- recog_resp$subID[which.min(recog_resp$acc)]
```

No transformation is needed. Log wouldn't help. Logit doesn't do much. 

Subject ID `r bad_outlier` should be removed.

```{r kill-outlier}
fa_sub <- fa_sub %>% filter(subID != bad_outlier)
fa_wide <- fa_wide %>% filter(subID != bad_outlier)
fa_wide_means <- fa_wide_means %>% filter(subID != bad_outlier)
recog_resp <- recog_resp %>% filter(subID != bad_outlier)
wr <- wr %>% filter(subID != bad_outlier)
# grab the slopes
fits <- wr %>%
  group_by(subID) %>%
  group_modify( ~ {
    as.data.frame(summary(
      lme4::lmer(drawduration ~ block + (1 | stimulus), data=.x)
    )$coefficients[2,,drop=FALSE])
  })
all_resp <- full_join(recog_resp, fits) %>%
  select(subID, rt, acc, Estimate) %>%
  rename(learn = Estimate) %>%
  mutate(learn = -learn) %>%
  filter()
```

# Lasso changes when re-estimated?

Yes. Due to cv. There are too few observations for 10 fold CV. Below we use AIC.

# Tradeoff btw `acc` and `rt`?

See above figure. Seemingly no. `rt` is pretty constant (at least btw subjects). I'd actually drop it from analysis.

# Fit 1: relaxed lasso on means for selected tracks (no grouping)

```{r}
y <- as.matrix(all_resp %>% select(-subID))
x <- fa_wide_means %>% 
  ungroup() %>% 
  dplyr::select(-subID) %>% 
  as.matrix()
bad_obs <- rowSums(is.na(x))
bad_cols <- colSums(is.na(x[bad_obs < 4,]))
x <- x[bad_obs < 4, bad_cols < 1]
```

* for now, we proceed with the mean FA as the predictor
* We also lose the following regions (due to `NA`s):

```{r}
names(bad_cols)[bad_cols>0]
```

```{r}
fitter_glmnet <- function(y) {
  yy <- y[bad_obs < 4]
  mod <- glmnet(x, yy / sd(yy), relax = TRUE, gamma = 0)
  aic <- log(colMeans((yy / sd(yy) - predict(mod, newx = x))^2)) +
    2 * mod$df / length(yy) 
  cc <- coef(mod, s = mod$lambda[which.min(aic)])
  data.frame(t(as.matrix(cc)))
}

mean_model_lasso <- lapply(all_resp %>% select(-subID), fitter_glmnet) %>%
  bind_rows() %>%
  mutate(resp = colnames(y)) %>%
  pivot_longer(-resp) %>%
  filter(abs(value) > 0)

ggplot(mean_model_lasso, aes(value, name, color = resp)) +
  geom_point() + 
  theme_bw() +
  geom_vline(xintercept = 0) +
  scale_color_brewer(palette = "Set1") +
  ylab("")
```

### Confidence intervals for this fit.

Note that the coefficients are on the scale of the data now, but the design matrix has to be standardized. We invert it

```{r glmnet-cis}
library(selectiveInference)
n <- nrow(y)
p <- ncol(x)
xm <- colMeans(x)
xstd <- x - rep(xm, rep(n, p))
xs <- drop(rep(1/n, n) %*% xstd^2)^0.5
xstd <- xstd / rep(xs, rep(n, p))

ci_glmnet <- function(y) {
  yy <- y[bad_obs < 4]
  mod <- glmnet(xstd, yy, relax = TRUE, gamma = 0, standardize = FALSE)
  aic <- log(colMeans((yy - predict(mod, newx = xstd))^2)) +
    2 * mod$df / n 
  lam <- mod$lambda[which.min(aic)]
  cc <- coef(mod, s = lam)[-1]
  res <- fixedLassoInf(xstd, yy , cc, lam*n)
  tibble(var = names(res$vars),
         est = res$coef0 / xs[res$vars],
         cilow = res$ci[,1] / xs[res$vars],
         cihi = res$ci[,2] / xs[res$vars])

}

cis <- map_dfr(
  as_tibble(y[,2:3]), ci_glmnet, .id = "response")
```

Now we plot them

```{r ci-plot}
better_labels = c(acc = "Accuracy", learn = "Learning")
cis %>%
  ggplot(aes(est, var, color = var)) +
  geom_point() +
  geom_errorbar(aes(xmin=cilow, xmax = cihi)) +
  facet_wrap(~response, scales = "free", 
             labeller = labeller(response = better_labels)) +
  theme_bw() +
  labs(x = "Coefficient estimate", y="") +
  geom_vline(xintercept = 0) +
  theme(legend.position = "none") +
  scale_color_brewer(palette = "Dark2")
```

### Same thing, but just using lm on the selected groups

```{r lm-cis}
ci_select_lm <- function(y) {
  yy <- y[bad_obs < 4]
  mod <- glmnet(xstd, yy, relax = TRUE, gamma = 0, standardize = FALSE)
  aic <- log(colMeans((yy - predict(mod, newx = xstd))^2)) +
    2 * mod$df / n 
  lam <- mod$lambda[which.min(aic)]
  cc <- coef(mod, s = lam)[-1]
  res <- fixedLassoInf(xstd, yy , cc, lam*n)
  mod2 <- lm(yy ~ x[,res$vars])
  conf <- confint(mod2, level = .9)
  tibble(var = names(res$vars),
         est = coef(mod2)[-1] ,
         cilow = conf[-1,1],
         cihi = conf[-1,2])
}

lm_cis <- map_dfr(
  as_tibble(y[,2:3]), ci_select_lm, .id = "response")
```

```{r lm-ci-plot}
lm_cis %>%
  ggplot(aes(est, var, color = var)) +
  geom_point() +
  geom_errorbar(aes(xmin=cilow, xmax = cihi)) +
  facet_wrap(~response, scales = "free", 
             labeller = labeller(response = better_labels)) +
  theme_bw() +
  labs(x = "Coefficient estimate", y="") +
  geom_vline(xintercept = 0) +
  theme(legend.position = "none") +
  scale_color_brewer(palette = "Dark2")
```




## Fit 2: just do lm on everything

```{r try-lm}
df <- inner_join(all_resp, fa_wide_means) %>% 
  dplyr::select(-subID) %>%
  mutate(across(c("rt", "acc", "learn"), ~.x/sd(.x)))
out <- lm(cbind(rt, acc, learn) ~ . , data = df)
coef(out) %>% 
  as_tibble(rownames = "coef") %>%
  pivot_longer(-coef) %>%
  ggplot(aes(value, coef, color = name)) +
  geom_point() + 
  theme_bw() +
  geom_vline(xintercept = 0) +
  scale_color_brewer(palette = "Set1") +
  ylab("")
```

# Group lasso

I wouldn't bother with group lasso on the mean model. Just lasso (relaxed), or `lm`.

If you want to do group lasso (or sparse gl), I see 4 options

1. For each tract, use all nodes. The groups are PVP/Dorsal/Ventral
1. For each tract, use all nodes. The groups are the tracts.
1. For each tract, use a basis expansion (5-10 df). The groups are PVP/Dorsal/Ventral
1. For each tract, use a basis expansion. The groups are the tracts.

I think 1 and 3 won't work well. I'd suggest 2 or 4.

## Let's try No. 4

This doesn't work well for some reason. CV wants the null model while AIC wants the saturated model. 

```{r make-splines}
df = 8
fa_wide_spline <- fa_sub %>%
  filter(nodeID > 20, nodeID < 181) %>%
  group_by(subID, tractname) %>%
  group_modify( ~ {
    if (sum(!is.na(.x$fa)) < df + 2)
      return(data.frame(nms = 1:df, cc = NA))
    out = lm(fa ~ splines::bs(nodeID, df=df, intercept = TRUE) - 1, data = .x)
    data.frame(nms = 1:df, cc = coef(out))
  })
fa_wide_spline <- fa_wide_spline %>%
  pivot_wider(names_from = c(tractname, nms), values_from = cc)
```

```{r sparsegl}
library(sparsegl)
x <- fa_wide_spline %>% 
  ungroup() %>% 
  dplyr::select(-subID) %>% 
  as.matrix()
gr <- rle(str_extract(colnames(x), "^[^_]*"))$lengths
gr <- rep(1:length(gr), times = gr)
y <- as.matrix(all_resp %>% dplyr::select(-subID))
set.seed(12345)
asparse = .25
fitter_sgl <- function(y) {
  yy <- y[bad_obs < 4]
  mod <- sparsegl(x, yy / sd(yy), group = gr, lambda.factor = 1e-4, asparse = asparse)
  aic <- estimate_risk(mod, x, type = "AIC")$AIC
  print(spot <- which.min(aic))
  cc <- coef(mod, s = mod$lambda[spot])
  data.frame(t(as.matrix(cc)))
}

bad_obs <- rowSums(is.na(x))
bad_cols <- colSums(is.na(x[bad_obs < 4,]))
x <- x[bad_obs < 4,]


model_sgl <- lapply(all_resp %>% dplyr::select(-subID), fitter_sgl) %>%
  bind_rows() %>%
  mutate(resp = colnames(y)) %>%
  pivot_longer(-resp) %>%
  filter(abs(value) > 0) %>%
  mutate(region = str_extract(name, "^[^_]*")) %>%
  group_by(resp, region) %>%
  summarise(norm = (1-asparse) * sqrt(sum(value^2)) + 
              asparse * sum(abs(value)))
```

Here we plot the norms of the groups (always positive).

```{r sparsegl-plot}
model_sgl %>%
  ggplot(aes(norm, region, color = resp)) +
  geom_point() + 
  theme_bw() +
  geom_vline(xintercept = 0) +
  scale_color_brewer(palette = "Set1") +
  ylab("")

```

